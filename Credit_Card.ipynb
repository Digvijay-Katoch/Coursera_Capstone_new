{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "VQ3syspj_rKn"
            },
            "source": "# Kernel PCA"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "xJGl9TcT_skx"
            },
            "source": "## Importing the libraries"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "BNEgrGwd_29D"
            },
            "outputs": [],
            "source": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n!pip install -q xlrd"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Hyp1gza1_6qX"
            },
            "source": "## Importing the dataset\n\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "lPLTDBVI__ZQ"
            },
            "outputs": [],
            "source": "dataset = pd.read_excel('CCDR.xls')\nX = dataset.iloc[:, 1:-1].values\ny = dataset.iloc[:, -1].values"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "8a-x0UnN3_6d",
                "outputId": "46107ba6-973a-4ec1-9286-269faa88cc11"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "20000\n"
                }
            ],
            "source": "print(X[0][0])"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "3bUhSHktAcOe"
            },
            "source": "## Splitting the dataset into the Training set and Test set"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "L7hGLt1qAced"
            },
            "outputs": [],
            "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "1wrHODfJAEiI"
            },
            "source": "## Feature Scaling"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "W-UCD7ezAJG2"
            },
            "outputs": [],
            "source": "from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "S3i3lRiwASAX"
            },
            "source": "## Applying Kernel PCA"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "TAi_sSw9AVzI",
                "outputId": "1399802d-a892-4376-e1e9-1046c45cfb46"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:463: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 2 - 1) = 1 components.\n  ChangedBehaviorWarning)\n/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:469: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n  warnings.warn(future_msg, FutureWarning)\n"
                }
            ],
            "source": "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nlda = LDA(n_components = 2)\nX_train = lda.fit_transform(X_train, y_train)\nX_test = lda.transform(X_test)"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "UBx16JVLAuel"
            },
            "source": "## Training the Logistic Regression model on the Training set"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "XDQahsqTAy44",
                "outputId": "f665f4d8-a454-416f-ac6c-8b2eb737d10e"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)"
                    },
                    "execution_count": 7,
                    "metadata": {
                        "tags": []
                    },
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "MTck416XBPnD"
            },
            "source": "## Making the Confusion Matrix"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "2LO7H5LsBS1b",
                "outputId": "bf9d837d-8e2b-43ca-b1e8-d49f9d413f68"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[[4600  103]\n [ 994  303]]\n"
                },
                {
                    "data": {
                        "text/plain": "0.8171666666666667"
                    },
                    "execution_count": 8,
                    "metadata": {
                        "tags": []
                    },
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "h6pZMBrUBXwb"
            },
            "source": "## Visualising the Training set results"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 279
                },
                "id": "FK_LpLOeBdQ4",
                "outputId": "d119ec06-fbc5-409f-8fc7-d79206477d84"
            },
            "outputs": [
                {
                    "ename": "IndexError",
                    "evalue": "ignored",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-12-dd6b094e0042>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n\u001b[0;32m----> 4\u001b[0;31m                      np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n\u001b[0m\u001b[1;32m      5\u001b[0m plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n\u001b[1;32m      6\u001b[0m              alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
                        "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
                    ]
                }
            ],
            "source": "from matplotlib.colors import ListedColormap\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Logistic Regression (Training set)')\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.legend()\nplt.show()\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "-Dbzx_KqBguX"
            },
            "source": "## Visualising the Test set results"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "kk07XbUHBl0W"
            },
            "outputs": [],
            "source": "from matplotlib.colors import ListedColormap\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Logistic Regression (Test set)')\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.legend()\nplt.show()"
        }
    ],
    "metadata": {
        "colab": {
            "collapsed_sections": [],
            "name": "Credit Card.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}